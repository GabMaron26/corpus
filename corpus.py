# -*- coding: utf-8 -*-
"""Corpus

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IlYpVoFz8qpj_7tFLz4XhohL_i-kA8bi
"""

# -*- coding: utf-8 -*-
"""ConstrucaoDoCorpus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19GSqVOQOvOee38dgh8orlF3mob-bFXs-
"""

#GABRIEL MARON MACHADO LIMA

#Sua  tarefa  será  transformar  um  conjunto  de  5  sites,  sobre  o  tema  de  processamento  de 
#linguagem natural em um conjunto de cinco listas distintas de sentenças. Ou seja, você fará uma função 
#que, usando a biblioteca Beautifull Soap, faça a requisição de uma url, e extrai todas as sentenças desta 
#url. Duas condições são importantes:  
#a) A página web (url) deve apontar para uma página web em inglês contendo, não menos que 
#1000 palavras.  
#b) O texto desta página deverá ser transformado em um array de senteças.  

import requests
from bs4 import BeautifulSoup


x = requests.get('https://towardsdatascience.com/introduction-to-natural-language-processing-for-text-df845750fb63')
st = BeautifulSoup(x.text, "html.parser")
sc = []
for x in st.find_all("p"):
    sc.append(x.get_text())
print('Primeiro site:')
print(sc)
print("*¨¨*¨¨*¨¨*¨¨*¨¨*\n")

x = requests.get('https://www.linguamatics.com/what-text-mining-text-analytics-and-natural-language-processing')
st = BeautifulSoup(x.text, "html.parser")
sc = []
for x in st.find_all("p"):
    sc.append(x.get_text())
print('Segundo site:')
print(sc)
print("*¨¨*¨¨*¨¨*¨¨*¨¨*\n")

x = requests.get('https://www.techtarget.com/searchenterpriseai/definition/natural-language-processing-NLP')
st = BeautifulSoup(x.text, "html.parser")
sc = []
for x in st.find_all("p"):
    sc.append(x.get_text())
print('Terceiro site:')
print(sc)
print("*¨¨*¨¨*¨¨*¨¨*¨¨*\n")

x = requests.get('https://en.wikipedia.org/wiki/Natural_language_processing')
st = BeautifulSoup(x.text, "html.parser")
sc = []
for x in st.find_all("p"):
    sc.append(x.get_text())
print('Quarto site:')
print(sc)
print("*¨¨*¨¨*¨¨*¨¨*¨¨*\n")

x = requests.get('https://monkeylearn.com/blog/natural-language-processing-techniques/')
st = BeautifulSoup(x.text, "html.parser")
sc = []
for x in st.find_all("p"):
    sc.append(x.get_text())
print('Quinto site:')
print(sc)
print("*¨¨*¨¨*¨¨*¨¨*¨¨*\n")